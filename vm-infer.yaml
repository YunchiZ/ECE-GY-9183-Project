version: "3.8"

x-minio-env: &minio-env
    MINIO_URL: http://${FIP_OPS}:9000
    MINIO_ACCESS_KEY: minioadmin
    MINIO_SECRET_KEY: minioadmin123

services:
    triton:
        image: nvcr.io/nvidia/tritonserver:23.09-py3
        runtime: nvidia
        shm_size: "8g"
        command: >
            tritonserver --model-repository=/models
                         --model-control-mode=poll
                         --strict-model-config=true
                         --http-port=8000   # 容器内部仍使用8000端口
                         --grpc-port=8001
                         --metrics-port=8002
                         --log-verbose=1
        ports:
            - "8003:8000"
            - "8001:8001"
            - "8002:8002"
        volumes:
            - /mnt/object/models:/models
        # cpus: "32"
        # cpu_shares: 2048
        networks: [mlops]
        restart: on-failure

    deploy:
        build:
            context: ./deploy
            dockerfile: Dockerfile.deploy
        environment:
            <<: *minio-env
        volumes:
            - /mnt/object/models:/app/models
            - ./deploy_data:/app/deploy_data
        ports: ["8080:8000"]
        depends_on: [triton]
        # cpus: "8"
        # cpu_shares: 512
        restart: always
        networks: [mlops]

    monitor:
        build:
            context: ./monitor
            dockerfile: Dockerfile.monitor
        environment:
            <<: *minio-env
            ETL_URL: http://${FIP_TRAIN}:8010
        volumes:
            - ./deploy_data:/app/deploy_data
            - ./monitor_data:/app/monitor_data
        ports: ["8030:8000"]
        depends_on: [deploy]
        # cpus: "8"
        # cpu_shares: 512
        restart: always
        networks: [mlops]

networks:
    mlops:
        driver: bridge
